{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14977d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import docker\n",
    "import time\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import os\n",
    "import ctypes as ct\n",
    "import multiprocessing\n",
    "import rapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ec141d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JOULES',\n",
       " 'MILLIJOULES',\n",
       " 'RAPLDifference',\n",
       " 'RAPLDomain',\n",
       " 'RAPLMonitor',\n",
       " 'RAPLSample',\n",
       " 'UJOULES',\n",
       " 'WATT_HOURS',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'datetime',\n",
       " 'os',\n",
       " 'rapl',\n",
       " 're']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(rapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f52923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cores: 48\n"
     ]
    }
   ],
   "source": [
    "# Discover the hardware architecture.\n",
    "avail_cores = os.cpu_count()\n",
    "print(f\"Available cores: {avail_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run docker-activity to monitor power consumption and runtime of the containers.\n",
    "\n",
    "# Initialize Docker client\n",
    "client = docker.from_env()\n",
    "activity_container = client.containers.run(\n",
    "    image=\"jdrouet/docker-activity\",\n",
    "    command=[\"stdout\"],\n",
    "    volumes={\n",
    "        \"/sys/class/powercap\": {\"bind\": \"/sys/class/powercap\", \"mode\": \"ro\"},\n",
    "        \"/var/run/docker.sock\": {\"bind\": \"/var/run/docker.sock\", \"mode\": \"rw\"},\n",
    "    },\n",
    "    privileged=True,\n",
    "    detach=True,\n",
    "    auto_remove=True\n",
    ")\n",
    "for log in activity_container.logs(stream=True, follow=True):\n",
    "    print(log.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175f5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    }
   ],
   "source": [
    "s1 = rapl.RAPLMonitor.sample()\n",
    "# some code to measure\n",
    "s2 = rapl.RAPLMonitor.sample()\n",
    "print((s2 - s1).energy(\"package-0\", \"core\", rapl.UJOULES))\n",
    "rapl.R\n",
    "\n",
    "# Read total energy at T0\n",
    "# Run the isolated benchmarks\n",
    "# Read total CPU time of each container during benchmark execution\n",
    "# Read total energy at T1 after benchmarks are finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "334ae86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container started for Disk benchmark (prepare).\n",
      "Container for benchmark ['sysbench', '--test=cpu', '--num-threads=8', '--cpu-max-prime=800000000000', 'run'] started successfully.\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=1M', '--memory-total-size=10G', '--threads=1', 'run'] started successfully.\n",
      "Container lifetime: 0.164251 seconds\n",
      "Container on CPU 1 completed and removed.\n",
      "Container lifetime: 9.617084 seconds\n",
      "Container on CPU 2 completed and removed.\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=50G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=300', '--max-requests=0', 'run'] started successfully.\n",
      "Container lifetime: 0.468979 seconds\n",
      "Container on CPU 3 completed and removed.\n",
      "Disk benchmark completed.\n",
      "All isolated benchmarks completed.\n"
     ]
    }
   ],
   "source": [
    "# Run isolated benchmarks in a Docker container on the different cores.\n",
    "def parse_start_time(start_time_str):\n",
    "    # Trim to microseconds and remove trailing 'Z'\n",
    "    if '.' in start_time_str:\n",
    "        time_part, rest = start_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(start_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def parse_die_time(die_time_str):\n",
    "    if '.' in die_time_str:\n",
    "        time_part, rest = die_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(die_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def run_container(task):\n",
    "    container = task['client'].containers.run(\n",
    "        image=task['image'],\n",
    "        command=task['command'],\n",
    "        cpuset_cpus=task['cpuset_cpus'],\n",
    "        cgroupns=\"private\",\n",
    "        detach=True,\n",
    "        labels={\"test\": next((arg.split('=')[1] for arg in task['command'] if arg.startswith('--test=')), None)}\n",
    "    )\n",
    "    max_retries = 5\n",
    "    retry_interval = 1\n",
    "    start_time = None  \n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        container.reload()\n",
    "        # Capture container metadata\n",
    "        if container.status == 'running':\n",
    "            started_at = container.attrs['State']['StartedAt']\n",
    "            start_time = parse_start_time(started_at)\n",
    "            print(f\"Container for benchmark {task['command']} started successfully.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying in {retry_interval} seconds...\")\n",
    "            time.sleep(retry_interval)\n",
    "    \n",
    "    # Ensure start_time is set even if the container does not reach 'running'\n",
    "    if start_time is None:\n",
    "        started_at = container.attrs['State']['StartedAt']\n",
    "        start_time = parse_start_time(started_at)\n",
    "    \n",
    "    container.stop()\n",
    "    container.reload()\n",
    "    died_at = container.attrs['State']['FinishedAt']\n",
    "    die_time = parse_die_time(died_at)\n",
    "    container_lifetime = (die_time - start_time).total_seconds()\n",
    "    print(f\"Container lifetime: {container_lifetime} seconds\")\n",
    "    isolated_benchmarking_results[container.name] = {\n",
    "        # 'workload': container.attrs['Config']['Labels'],\n",
    "        'coloc_pair': None,\n",
    "        'workload': container.attrs['Config']['Labels'].get('test', None), \n",
    "        'id': container.id,\n",
    "        'life_time': container_lifetime,\n",
    "    }\n",
    "    container.remove()\n",
    "    print(f\"Container on CPU {task['cpuset_cpus']} completed and removed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "            \n",
    "    # Initialize Docker client\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    # Prepare affinity score map for colocated pairs.\n",
    "    isolated_benchmarking_results = {}\n",
    "\n",
    "    # Init the disk benchmark.\n",
    "    print(\"Container started for Disk benchmark (prepare).\")\n",
    "    disk_prepare_output = client.containers.run(\n",
    "    image=\"niklas/sysbench\",\n",
    "    command=[\n",
    "        \"sysbench\", \"--test=fileio\",\n",
    "        \"--file-total-size=50G\",\n",
    "        \"--file-test-mode=rndrw\",\n",
    "        \"--num-threads=1\",\n",
    "        \"prepare\"\n",
    "    ],\n",
    "    cpuset_cpus=\"1\",\n",
    "    cgroupns=\"private\",\n",
    "    detach=False, \n",
    "    auto_remove=True  \n",
    "    )\n",
    "\n",
    "    # List of dictionaries to hold task information.\n",
    "    tasks = [\n",
    "        {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=cpu\", \"--num-threads=8\", \"--cpu-max-prime=800000000000\",\"run\"], \"cpuset_cpus\": \"1\"},\n",
    "        {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=1M\", \"--memory-total-size=10G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"2\"},\n",
    "        {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=50G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=300\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"3\"}\n",
    "    ]\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2, thread_name_prefix=\"Isolator\") as executor:\n",
    "        futures = [executor.submit(run_container, task) for task in tasks]\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "    \n",
    "    # Disk cleanup\n",
    "    disk_cleanup_output = client.containers.run(\n",
    "        image=\"niklas/sysbench\",\n",
    "        command=[\n",
    "            \"sysbench\", \"--test=fileio\",\n",
    "            \"cleanup\"\n",
    "        ],\n",
    "        cpuset_cpus=\"3\",\n",
    "        detach=False,  \n",
    "        auto_remove=True  \n",
    "    )\n",
    "    print(\"Disk benchmark completed.\")\n",
    "        \n",
    "    print(\"All isolated benchmarks completed.\")\n",
    "    # Clean up Docker client\n",
    "    client.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f3185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container started for Disk benchmark (prepare).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Init the disk benchmark.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContainer started for Disk benchmark (prepare).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m disk_prepare_output \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mniklas/sysbench\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msysbench\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--test=fileio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--file-total-size=50G\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--file-test-mode=rndrw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--num-threads=1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprepare\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43mcpuset_cpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43mcgroupns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprivate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43mdetach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43mauto_remove\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# List of dictionaries to hold task information.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     93\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m: client, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinpack\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpuset_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     94\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m: client, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mniklas/sysbench\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msysbench\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--test=memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--memory-block-size=1M\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--memory-total-size=10G\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--threads=1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpuset_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     95\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m: client,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mniklas/sysbench\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msysbench\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--test=fileio\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--file-total-size=50G\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--file-test-mode=rndrw\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--init-rng=on\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--max-time=300\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--max-requests=0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpuset_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     96\u001b[0m ]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/docker/models/containers.py:896\u001b[0m, in \u001b[0;36mContainerCollection.run\u001b[0;34m(self, image, command, stdout, stderr, remove, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_driver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson-file\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m logging_driver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjournald\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    892\u001b[0m     out \u001b[38;5;241m=\u001b[39m container\u001b[38;5;241m.\u001b[39mlogs(\n\u001b[1;32m    893\u001b[0m         stdout\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, follow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     )\n\u001b[0;32m--> 896\u001b[0m exit_status \u001b[38;5;241m=\u001b[39m \u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatusCode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exit_status \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    898\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/docker/models/containers.py:528\u001b[0m, in \u001b[0;36mContainer.wait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    508\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m    Block until the container stops, then return its exit code. Similar to\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    the ``docker wait`` command.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m            If the server returns an error.\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/docker/utils/decorators.py:19\u001b[0m, in \u001b[0;36mcheck_resource.<locals>.decorator.<locals>.wrapped\u001b[0;34m(self, resource_id, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_id:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNullResource(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResource ID was not provided\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/docker/api/container.py:1347\u001b[0m, in \u001b[0;36mContainerApiMixin.wait\u001b[0;34m(self, container, timeout, condition)\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidVersion(\n\u001b[1;32m   1343\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwait condition is not supported for API version < 1.30\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1344\u001b[0m         )\n\u001b[1;32m   1345\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m condition\n\u001b[0;32m-> 1347\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result(res, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/docker/utils/decorators.py:44\u001b[0m, in \u001b[0;36mupdate_headers.<locals>.inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_general_configs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHttpHeaders\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/docker/api/client.py:242\u001b[0m, in \u001b[0;36mAPIClient._post\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;129m@update_headers\u001b[39m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_request_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/urllib3/response.py:1063\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/urllib3/response.py:1219\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1216\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/sharecomp-bB4WWry4-py3.10/lib/python3.10/site-packages/urllib3/response.py:1138\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Uses linpack | Run isolated benchmarks in a Docker container on the different cores.\n",
    "def parse_start_time(start_time_str):\n",
    "    # Trim to microseconds and remove trailing 'Z'\n",
    "    if '.' in start_time_str:\n",
    "        time_part, rest = start_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(start_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def parse_die_time(die_time_str):\n",
    "    if '.' in die_time_str:\n",
    "        time_part, rest = die_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(die_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def run_container(task):\n",
    "    label = task.get(\"label\")\n",
    "    if label is None:\n",
    "        label = next((arg.split('=')[1] for arg in task['command'] if arg.startswith('--test=')), None)\n",
    "    container = task['client'].containers.run(\n",
    "        image=task['image'],\n",
    "        command=task['command'],\n",
    "        cpuset_cpus=task['cpuset_cpus'],\n",
    "        cgroupns=\"private\",\n",
    "        detach=True,\n",
    "        labels = {\"test\": label}\n",
    "    )\n",
    "    max_retries = 5\n",
    "    retry_interval = 1\n",
    "    start_time = None  \n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        container.reload()\n",
    "        # Capture container metadata\n",
    "        if container.status == 'running':\n",
    "            started_at = container.attrs['State']['StartedAt']\n",
    "            start_time = parse_start_time(started_at)\n",
    "            print(f\"Container for benchmark {task['command']} started successfully.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying in {retry_interval} seconds...\")\n",
    "            time.sleep(retry_interval)\n",
    "    \n",
    "    # Ensure start_time is set even if the container does not reach 'running'\n",
    "    if start_time is None:\n",
    "        started_at = container.attrs['State']['StartedAt']\n",
    "        start_time = parse_start_time(started_at)\n",
    "    \n",
    "    container.stop()\n",
    "    container.reload()\n",
    "    died_at = container.attrs['State']['FinishedAt']\n",
    "    die_time = parse_die_time(died_at)\n",
    "    container_lifetime = (die_time - start_time).total_seconds()\n",
    "    print(f\"Container lifetime: {container_lifetime} seconds\")\n",
    "    isolated_benchmarking_results[container.name] = {\n",
    "        # 'workload': container.attrs['Config']['Labels'],\n",
    "        'coloc_pair': None,\n",
    "        'workload': container.attrs['Config']['Labels'].get('test', None), \n",
    "        'id': container.id,\n",
    "        'life_time': container_lifetime,\n",
    "    }\n",
    "    container.remove()\n",
    "    print(f\"Container on CPU {task['cpuset_cpus']} completed and removed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "            \n",
    "    # Initialize Docker client\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    # Prepare affinity score map for colocated pairs.\n",
    "    isolated_benchmarking_results = {}\n",
    "\n",
    "    # Init the disk benchmark.\n",
    "    print(\"Container started for Disk benchmark (prepare).\")\n",
    "    disk_prepare_output = client.containers.run(\n",
    "    image=\"niklas/sysbench\",\n",
    "    command=[\n",
    "        \"sysbench\", \"--test=fileio\",\n",
    "        \"--file-total-size=50G\",\n",
    "        \"--file-test-mode=rndrw\",\n",
    "        \"--num-threads=1\",\n",
    "        \"prepare\"\n",
    "    ],\n",
    "    cpuset_cpus=\"1\",\n",
    "    cgroupns=\"private\",\n",
    "    detach=False, \n",
    "    auto_remove=True  \n",
    "    )\n",
    "\n",
    "    # List of dictionaries to hold task information.\n",
    "    tasks = [\n",
    "        {\"client\": client, \"image\": \"linpack\", \"command\": [\"linpack\"], \"cpuset_cpus\": \"1\", \"label\":\"cpu\"},\n",
    "        {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=1M\", \"--memory-total-size=10G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"2\"},\n",
    "        {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=50G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=300\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"3\"}\n",
    "    ]\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2, thread_name_prefix=\"Isolator\") as executor:\n",
    "        futures = [executor.submit(run_container, task) for task in tasks]\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "    \n",
    "    # Disk cleanup\n",
    "    disk_cleanup_output = client.containers.run(\n",
    "        image=\"niklas/sysbench\",\n",
    "        command=[\n",
    "            \"sysbench\", \"--test=fileio\",\n",
    "            \"cleanup\"\n",
    "        ],\n",
    "        cpuset_cpus=\"3\",\n",
    "        detach=False,  \n",
    "        auto_remove=True  \n",
    "    )\n",
    "    print(\"Disk benchmark completed.\")\n",
    "        \n",
    "    print(\"All isolated benchmarks completed.\")\n",
    "    # Clean up Docker client\n",
    "    client.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9752175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container names and IDs:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'isolated_benchmarking_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Access the watched benchmark containers for runtime and power consumption.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContainer names and IDs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, container_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43misolated_benchmarking_results\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontainer_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'isolated_benchmarking_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Access the watched benchmark containers for runtime and power consumption.\n",
    "print(\"Container names and IDs:\")\n",
    "for name, container_id in isolated_benchmarking_results.items():\n",
    "    print(f\"{name}: {container_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdec2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container started for Disk benchmark (prepare).\n",
      "Running colocated tasks for: CpuMem\n",
      "Container for benchmark ['sysbench', '--test=cpu', '--num-threads=8', '--cpu-max-prime=40000000000', 'run'] started successfully.\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container lifetime: 0.176359 seconds\n",
      "Container on CPU 0 completed and removed.\n",
      "Container lifetime: 6.177636 seconds\n",
      "Container on CPU 24 completed and removed.\n",
      "Completed colocated tasks for: CpuMem\n",
      "Running colocated tasks for: MemFileIO\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=150G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=300', '--max-requests=0', 'run'] started successfully.\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container lifetime: 0.47887 seconds\n",
      "Container on CPU 25 completed and removed.\n",
      "Container lifetime: 6.304723 seconds\n",
      "Container on CPU 1 completed and removed.\n",
      "Completed colocated tasks for: MemFileIO\n",
      "Running colocated tasks for: FileIOCpu\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=300G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=1800', '--max-requests=0', 'run'] started successfully.\n",
      "Container lifetime: 0.375121 seconds\n",
      "Container on CPU 26 completed and removed.\n",
      "Container for benchmark ['sysbench', '--test=cpu', '--num-threads=8', '--cpu-max-prime=40000000000', 'run'] started successfully.\n",
      "Container lifetime: 1.206917 seconds\n",
      "Container on CPU 2 completed and removed.\n",
      "Completed colocated tasks for: FileIOCpu\n",
      "Running colocated tasks for: CpuCpu\n",
      "Container for benchmark ['sysbench', '--test=cpu', '--num-threads=8', '--cpu-max-prime=40000000000', 'run'] started successfully.\n",
      "Container lifetime: 0.311122 seconds\n",
      "Container on CPU 3 completed and removed.\n",
      "Container for benchmark ['sysbench', '--test=cpu', '--num-threads=8', '--cpu-max-prime=40000000000', 'run'] started successfully.\n",
      "Container lifetime: 0.989985 seconds\n",
      "Container on CPU 27 completed and removed.\n",
      "Completed colocated tasks for: CpuCpu\n",
      "Running colocated tasks for: MemMem\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container lifetime: 10.225571 seconds\n",
      "Container on CPU 28 completed and removed.\n",
      "Container lifetime: 10.369342 seconds\n",
      "Container on CPU 4 completed and removed.\n",
      "Completed colocated tasks for: MemMem\n",
      "Running colocated tasks for: FileIOFileIO\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=300G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=1800', '--max-requests=0', 'run'] started successfully.\n",
      "Container lifetime: 0.294034 seconds\n",
      "Container on CPU 29 completed and removed.\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=300G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=1800', '--max-requests=0', 'run'] started successfully.\n",
      "Container lifetime: 1.23869 seconds\n",
      "Container on CPU 5 completed and removed.\n",
      "Completed colocated tasks for: FileIOFileIO\n",
      "Disk benchmark completed.\n",
      "All colocated benchmarks completed.\n"
     ]
    }
   ],
   "source": [
    "# Run co-located benchmarks in a Docker container on the same core.\n",
    "def parse_start_time(start_time_str):\n",
    "    # Trim to microseconds and remove trailing 'Z'\n",
    "    if '.' in start_time_str:\n",
    "        time_part, rest = start_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(start_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def parse_die_time(die_time_str):\n",
    "    if '.' in die_time_str:\n",
    "        time_part, rest = die_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(die_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "    \n",
    "def run_container(task):\n",
    "    container = task['client'].containers.run(\n",
    "        image=task['image'],\n",
    "        command=task['command'],\n",
    "        cpuset_cpus=task['cpuset_cpus'],\n",
    "        cgroupns=\"private\",\n",
    "        detach=True,\n",
    "        labels={\"test\": next((arg.split('=')[1] for arg in task['command'] if arg.startswith('--test=')), None)}\n",
    "    )\n",
    "    \n",
    "    max_retries = 5\n",
    "    retry_interval = 1\n",
    "    start_time = None  \n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        container.reload()\n",
    "        # Capture container metadata\n",
    "        if container.status == 'running':\n",
    "            started_at = container.attrs['State']['StartedAt']\n",
    "            start_time = parse_start_time(started_at)\n",
    "            print(f\"Container for benchmark {task['command']} started successfully.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying in {retry_interval} seconds...\")\n",
    "            time.sleep(retry_interval)\n",
    "    \n",
    "    if start_time is None:\n",
    "        started_at = container.attrs['State']['StartedAt']\n",
    "        start_time = parse_start_time(started_at)\n",
    "    \n",
    "    container.stop()\n",
    "    container.reload()\n",
    "    died_at = container.attrs['State']['FinishedAt']\n",
    "    die_time = parse_die_time(died_at)\n",
    "    container_lifetime = (die_time - start_time).total_seconds()\n",
    "    print(f\"Container lifetime: {container_lifetime} seconds\")\n",
    "    coloc_benchmarking_results[container.name] = {\n",
    "        'coloc_pair': pair_name,\n",
    "        'workload': container.attrs['Config']['Labels'].get('test', None),  \n",
    "        'id': container.id,\n",
    "        'colocated_runtime': container_lifetime,\n",
    "    }\n",
    "    container.remove()\n",
    "    print(f\"Container on CPU {task['cpuset_cpus']} completed and removed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Initialize Docker client\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    # Prepare affinity score map for colocated pairs.\n",
    "    coloc_benchmarking_results = {}\n",
    "\n",
    "    # Init the disk benchmark.\n",
    "    print(\"Container started for Disk benchmark (prepare).\")\n",
    "    disk_prepare_output = client.containers.run(\n",
    "    image=\"niklas/sysbench\",\n",
    "    command=[\n",
    "        \"sysbench\", \"--test=fileio\",\n",
    "        \"--file-total-size=300G\",\n",
    "        \"--file-test-mode=rndrw\",\n",
    "        \"--num-threads=1\",\n",
    "        \"prepare\"\n",
    "    ],\n",
    "    cpuset_cpus=\"1\",\n",
    "    cgroupns=\"private\",\n",
    "    detach=False, \n",
    "    auto_remove=True  \n",
    "    )\n",
    "\n",
    "    # Run every co-located benchmark combination on the same core.\n",
    "    colocation = [\n",
    "        {\"CpuMem\": [\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=cpu\", \"--num-threads=8\", \"--cpu-max-prime=40000000000\", \"run\"], \"cpuset_cpus\": \"0\"},\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"24\"}\n",
    "        ]},\n",
    "        {\"MemFileIO\": [\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"1\"},\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=150G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=300\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"25\"}\n",
    "        ]},\n",
    "        {\"FileIOCpu\": [\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=cpu\", \"--num-threads=8\", \"--cpu-max-prime=40000000000\", \"run\"], \"cpuset_cpus\": \"2\"},\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=300G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=1800\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"26\"}\n",
    "        ]},\n",
    "        {\"CpuCpu\": [\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=cpu\", \"--num-threads=8\", \"--cpu-max-prime=40000000000\", \"run\"], \"cpuset_cpus\": \"3\"},\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=cpu\", \"--num-threads=8\", \"--cpu-max-prime=40000000000\", \"run\"], \"cpuset_cpus\": \"27\"},\n",
    "        ]},\n",
    "        {\"MemMem\": [\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"4\"},\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"28\"},\n",
    "        ]},\n",
    "        {\"FileIOFileIO\": [\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=300G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=1800\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"5\"},\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=300G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=1800\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"29\"}\n",
    "        ]}\n",
    "    ]\n",
    "    \n",
    "    for coloc in colocation:\n",
    "            for pair_name, tasks in coloc.items():\n",
    "                print(f\"Running colocated tasks for: {pair_name}\")\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=2, thread_name_prefix=\"Colocator\") as executor:\n",
    "                    futures = [executor.submit(run_container, task) for task in tasks]\n",
    "                for future in futures:\n",
    "                    future.result()\n",
    "                print(f\"Completed colocated tasks for: {pair_name}\")\n",
    "    \n",
    "    # Disk cleanup\n",
    "    disk_cleanup_output = client.containers.run(\n",
    "        image=\"niklas/sysbench\",\n",
    "        command=[\n",
    "            \"sysbench\", \"--test=fileio\",\n",
    "            \"cleanup\"\n",
    "        ],\n",
    "        cpuset_cpus=\"3\",\n",
    "        detach=False,  \n",
    "        auto_remove=True  \n",
    "    )\n",
    "    print(\"Disk benchmark completed.\")\n",
    "        \n",
    "    print(\"All colocated benchmarks completed.\")\n",
    "    # Clean up Docker client\n",
    "    client.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2caf2432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container started for Disk benchmark (prepare).\n",
      "Running colocated tasks for: CpuMem\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container for benchmark ['linpack'] started successfully.\n",
      "Container lifetime: 6.161869 seconds\n",
      "Container on CPU 24 completed and removed.\n",
      "Container lifetime: 10.247913 seconds\n",
      "Container on CPU 1 completed and removed.\n",
      "Completed colocated tasks for: CpuMem\n",
      "Running colocated tasks for: MemFileIO\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=150G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=300', '--max-requests=0', 'run'] started successfully.\n",
      "Container lifetime: 0.386965 seconds\n",
      "Container on CPU 25 completed and removed.\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container lifetime: 7.176097 seconds\n",
      "Container on CPU 1 completed and removed.\n",
      "Completed colocated tasks for: MemFileIO\n",
      "Running colocated tasks for: FileIOCpu\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=300G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=1800', '--max-requests=0', 'run'] started successfully.\n",
      "Container lifetime: 0.208124 seconds\n",
      "Container on CPU 26 completed and removed.\n",
      "Container for benchmark ['linpack'] started successfully.\n",
      "Container lifetime: 10.838023 seconds\n",
      "Container on CPU 1 completed and removed.\n",
      "Completed colocated tasks for: FileIOCpu\n",
      "Running colocated tasks for: CpuCpu\n",
      "Container for benchmark ['linpack'] started successfully.\n",
      "Container for benchmark ['linpack'] started successfully.\n",
      "Container lifetime: 10.291559 seconds\n",
      "Container on CPU 1 completed and removed.\n",
      "Container lifetime: 10.364075 seconds\n",
      "Container on CPU 1 completed and removed.\n",
      "Completed colocated tasks for: CpuCpu\n",
      "Running colocated tasks for: MemMem\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container for benchmark ['sysbench', '--test=memory', '--memory-block-size=8M', '--memory-total-size=150G', '--threads=1', 'run'] started successfully.\n",
      "Container lifetime: 10.231874 seconds\n",
      "Container on CPU 28 completed and removed.\n",
      "Container lifetime: 10.272077 seconds\n",
      "Container on CPU 4 completed and removed.\n",
      "Completed colocated tasks for: MemMem\n",
      "Running colocated tasks for: FileIOFileIO\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=300G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=1800', '--max-requests=0', 'run'] started successfully.\n",
      "Container for benchmark ['sysbench', '--test=fileio', '--file-total-size=300G', '--file-test-mode=rndrw', '--init-rng=on', '--max-time=1800', '--max-requests=0', 'run'] started successfully.\n",
      "Container lifetime: 0.213043 seconds\n",
      "Container on CPU 29 completed and removed.\n",
      "Container lifetime: 0.269304 seconds\n",
      "Container on CPU 5 completed and removed.\n",
      "Completed colocated tasks for: FileIOFileIO\n",
      "Disk benchmark completed.\n",
      "All colocated benchmarks completed.\n"
     ]
    }
   ],
   "source": [
    "# Using linpack | Run co-located benchmarks in a Docker container on the same core.\n",
    "def parse_start_time(start_time_str):\n",
    "    # Trim to microseconds and remove trailing 'Z'\n",
    "    if '.' in start_time_str:\n",
    "        time_part, rest = start_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(start_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def parse_die_time(die_time_str):\n",
    "    if '.' in die_time_str:\n",
    "        time_part, rest = die_time_str.split('.')\n",
    "        microseconds = rest[:6]  \n",
    "        return datetime.strptime(f\"{time_part}.{microseconds}\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "    return datetime.strptime(die_time_str.replace('Z', ''), \"%Y-%m-%dT%H:%M:%S\")\n",
    "    \n",
    "def run_container(task):\n",
    "    label = task.get(\"label\")\n",
    "    if label is None:\n",
    "        label = next((arg.split('=')[1] for arg in task['command'] if arg.startswith('--test=')), None)\n",
    "    container = task['client'].containers.run(\n",
    "        image=task['image'],\n",
    "        command=task['command'],\n",
    "        cpuset_cpus=task['cpuset_cpus'],\n",
    "        cgroupns=\"private\",\n",
    "        detach=True,\n",
    "        labels={\"test\": label}\n",
    "    )\n",
    "    \n",
    "    max_retries = 5\n",
    "    retry_interval = 1\n",
    "    start_time = None  \n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        container.reload()\n",
    "        # Capture container metadata\n",
    "        if container.status == 'running':\n",
    "            started_at = container.attrs['State']['StartedAt']\n",
    "            start_time = parse_start_time(started_at)\n",
    "            print(f\"Container for benchmark {task['command']} started successfully.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Attempt {attempt + 1} failed, retrying in {retry_interval} seconds...\")\n",
    "            time.sleep(retry_interval)\n",
    "    \n",
    "    if start_time is None:\n",
    "        started_at = container.attrs['State']['StartedAt']\n",
    "        start_time = parse_start_time(started_at)\n",
    "    \n",
    "    container.stop()\n",
    "    container.reload()\n",
    "    died_at = container.attrs['State']['FinishedAt']\n",
    "    die_time = parse_die_time(died_at)\n",
    "    container_lifetime = (die_time - start_time).total_seconds()\n",
    "    print(f\"Container lifetime: {container_lifetime} seconds\")\n",
    "    coloc_benchmarking_results[container.name] = {\n",
    "        'coloc_pair': pair_name,\n",
    "        'workload': container.attrs['Config']['Labels'].get('test', None),  \n",
    "        'id': container.id,\n",
    "        'colocated_runtime': container_lifetime,\n",
    "    }\n",
    "    container.remove()\n",
    "    print(f\"Container on CPU {task['cpuset_cpus']} completed and removed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Initialize Docker client\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    # Prepare affinity score map for colocated pairs.\n",
    "    coloc_benchmarking_results = {}\n",
    "\n",
    "    # Init the disk benchmark.\n",
    "    print(\"Container started for Disk benchmark (prepare).\")\n",
    "    disk_prepare_output = client.containers.run(\n",
    "    image=\"niklas/sysbench\",\n",
    "    command=[\n",
    "        \"sysbench\", \"--test=fileio\",\n",
    "        \"--file-total-size=300G\",\n",
    "        \"--file-test-mode=rndrw\",\n",
    "        \"--num-threads=1\",\n",
    "        \"prepare\"\n",
    "    ],\n",
    "    cpuset_cpus=\"1\",\n",
    "    cgroupns=\"private\",\n",
    "    detach=False, \n",
    "    auto_remove=True  \n",
    "    )\n",
    "\n",
    "    # Run every co-located benchmark combination on the same core.\n",
    "    colocation = [\n",
    "        {\"CpuMem\": [\n",
    "            {\"client\": client, \"image\": \"linpack\", \"command\": [\"linpack\"], \"cpuset_cpus\": \"1\", \"label\": \"cpu\"},\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"24\"}\n",
    "        ]},\n",
    "        {\"MemFileIO\": [\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"1\"},\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=150G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=300\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"25\"}\n",
    "        ]},\n",
    "        {\"FileIOCpu\": [\n",
    "            {\"client\": client, \"image\": \"linpack\", \"command\": [\"linpack\"], \"cpuset_cpus\": \"1\", \"label\": \"cpu\"},\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=300G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=1800\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"26\"}\n",
    "        ]},\n",
    "        {\"CpuCpu\": [\n",
    "            {\"client\": client, \"image\": \"linpack\", \"command\": [\"linpack\"], \"cpuset_cpus\": \"1\", \"label\": \"cpu\"},\n",
    "            {\"client\": client, \"image\": \"linpack\", \"command\": [\"linpack\"], \"cpuset_cpus\": \"1\", \"label\": \"cpu\"},\n",
    "        ]},\n",
    "        {\"MemMem\": [\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"4\"},\n",
    "            {\"client\": client, \"image\": \"niklas/sysbench\", \"command\": [\"sysbench\", \"--test=memory\", \"--memory-block-size=8M\", \"--memory-total-size=150G\", \"--threads=1\", \"run\"], \"cpuset_cpus\": \"28\"},\n",
    "        ]},\n",
    "        {\"FileIOFileIO\": [\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=300G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=1800\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"5\"},\n",
    "            {\"client\": client,\"image\": \"niklas/sysbench\",\"command\": [\"sysbench\", \"--test=fileio\",\"--file-total-size=300G\",\"--file-test-mode=rndrw\",\"--init-rng=on\",\"--max-time=1800\",\"--max-requests=0\",\"run\"],\"cpuset_cpus\": \"29\"}\n",
    "        ]}\n",
    "    ]\n",
    "    \n",
    "    for coloc in colocation:\n",
    "            for pair_name, tasks in coloc.items():\n",
    "                print(f\"Running colocated tasks for: {pair_name}\")\n",
    "                with concurrent.futures.ThreadPoolExecutor(max_workers=2, thread_name_prefix=\"Colocator\") as executor:\n",
    "                    futures = [executor.submit(run_container, task) for task in tasks]\n",
    "                for future in futures:\n",
    "                    future.result()\n",
    "                print(f\"Completed colocated tasks for: {pair_name}\")\n",
    "    \n",
    "    # Disk cleanup\n",
    "    disk_cleanup_output = client.containers.run(\n",
    "        image=\"niklas/sysbench\",\n",
    "        command=[\n",
    "            \"sysbench\", \"--test=fileio\",\n",
    "            \"cleanup\"\n",
    "        ],\n",
    "        cpuset_cpus=\"3\",\n",
    "        detach=False,  \n",
    "        auto_remove=True  \n",
    "    )\n",
    "    print(\"Disk benchmark completed.\")\n",
    "        \n",
    "    print(\"All colocated benchmarks completed.\")\n",
    "    # Clean up Docker client\n",
    "    client.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfdca0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container names and IDs:\n",
      "eloquent_sutherland: {'coloc_pair': 'CpuMem', 'workload': 'memory', 'id': '30a982abcd6211ec01473caa5fdedc5340d3a0bb6db5dbe1e73ebed82471d017', 'colocated_runtime': 6.161869, 'isolated_runtime': 0.638697, 'isolated_power_consumption': 'not yet computed'}\n",
      "relaxed_gagarin: {'coloc_pair': 'CpuMem', 'workload': 'cpu', 'id': '2498536fe8d1f2b24834ed86b5aecadb278a3bf7493326ced6bc083d241b3bb1', 'colocated_runtime': 10.247913, 'isolated_runtime': 10.369488, 'isolated_power_consumption': 'not yet computed'}\n",
      "nifty_wilson: {'coloc_pair': 'MemFileIO', 'workload': 'fileio', 'id': '3e225ecf6ec7a378180c8214d3e9c8ab17fdeba10907692420282ab7ce7c952c', 'colocated_runtime': 0.386965, 'isolated_runtime': 0.168125, 'isolated_power_consumption': 'not yet computed'}\n",
      "dreamy_lamarr: {'coloc_pair': 'MemFileIO', 'workload': 'memory', 'id': '0dda809d09b83bc6891c779c43887eb6c5ed3da6bfa9562b447d490c54b98e5e', 'colocated_runtime': 7.176097, 'isolated_runtime': 0.638697, 'isolated_power_consumption': 'not yet computed'}\n",
      "zen_solomon: {'coloc_pair': 'FileIOCpu', 'workload': 'fileio', 'id': '8d09c0570811ad29d00248232def0722dd977ebbed920298850fd66308fe5399', 'colocated_runtime': 0.208124, 'isolated_runtime': 0.168125, 'isolated_power_consumption': 'not yet computed'}\n",
      "keen_visvesvaraya: {'coloc_pair': 'FileIOCpu', 'workload': 'cpu', 'id': 'ce1921fb238cd046c3eb589fac60e71d35f768ad22163fde4a6d2a6a3c621ac9', 'colocated_runtime': 10.838023, 'isolated_runtime': 10.369488, 'isolated_power_consumption': 'not yet computed'}\n",
      "cranky_cray: {'coloc_pair': 'CpuCpu', 'workload': 'cpu', 'id': '263dfff8f7e477f92a3ac7d47942c9efb4e419de83b55738259fb1f0898b527e', 'colocated_runtime': 10.291559, 'isolated_runtime': 10.369488, 'isolated_power_consumption': 'not yet computed'}\n",
      "wonderful_matsumoto: {'coloc_pair': 'CpuCpu', 'workload': 'cpu', 'id': 'e77f38c6950d1e4f1181de1aa15870035dcb76fd1cd03696a353931aa00aa875', 'colocated_runtime': 10.364075, 'isolated_runtime': 10.369488, 'isolated_power_consumption': 'not yet computed'}\n",
      "stupefied_goldwasser: {'coloc_pair': 'MemMem', 'workload': 'memory', 'id': '5e764376967f07da891e922ca9bb477e1e6e87ce051c3a6aceeacbf949cd0369', 'colocated_runtime': 10.231874, 'isolated_runtime': 0.638697, 'isolated_power_consumption': 'not yet computed'}\n",
      "upbeat_kirch: {'coloc_pair': 'MemMem', 'workload': 'memory', 'id': '4b8dff34270b713bece24136de6811ecd9560f40f3deb958e929bc10a6cad400', 'colocated_runtime': 10.272077, 'isolated_runtime': 0.638697, 'isolated_power_consumption': 'not yet computed'}\n",
      "quirky_solomon: {'coloc_pair': 'FileIOFileIO', 'workload': 'fileio', 'id': '4b4fa69c1b483533f750da83b10aa6cbd1d63f93448995467767b4793aae07af', 'colocated_runtime': 0.213043, 'isolated_runtime': 0.168125, 'isolated_power_consumption': 'not yet computed'}\n",
      "competent_franklin: {'coloc_pair': 'FileIOFileIO', 'workload': 'fileio', 'id': '51ec01e6d5eb85a018d6a09a9fac3d9036ef211cb29d23f80810cc5b58da59f4', 'colocated_runtime': 0.269304, 'isolated_runtime': 0.168125, 'isolated_power_consumption': 'not yet computed'}\n"
     ]
    }
   ],
   "source": [
    "# Access the watched benchmark containers for runtime and power consumption.\n",
    "coloc_benchmarking_results_copy = copy.deepcopy(coloc_benchmarking_results)\n",
    "\n",
    "print(\"Container names and IDs:\")\n",
    "for name, container_id in coloc_benchmarking_results.items():\n",
    "    print(f\"{name}: {container_id}\")\n",
    "# print(benchmarking_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3400975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colocated benchmark: memory, CpuMem, Isolated runtime: 0.638697\n",
      "Colocated benchmark: cpu, CpuMem, Isolated runtime: 10.369488\n",
      "Colocated benchmark: fileio, MemFileIO, Isolated runtime: 0.168125\n",
      "Colocated benchmark: memory, MemFileIO, Isolated runtime: 0.638697\n",
      "Colocated benchmark: fileio, FileIOCpu, Isolated runtime: 0.168125\n",
      "Colocated benchmark: cpu, FileIOCpu, Isolated runtime: 10.369488\n",
      "Colocated benchmark: cpu, CpuCpu, Isolated runtime: 10.369488\n",
      "Colocated benchmark: cpu, CpuCpu, Isolated runtime: 10.369488\n",
      "Colocated benchmark: memory, MemMem, Isolated runtime: 0.638697\n",
      "Colocated benchmark: memory, MemMem, Isolated runtime: 0.638697\n",
      "Colocated benchmark: fileio, FileIOFileIO, Isolated runtime: 0.168125\n",
      "Colocated benchmark: fileio, FileIOFileIO, Isolated runtime: 0.168125\n"
     ]
    }
   ],
   "source": [
    "def calc_average_slowdown(slowdown_1, slowdown_2):\n",
    "    average_slowdown = (slowdown_1 + slowdown_2) / 2\n",
    "    return average_slowdown\n",
    "\n",
    "def calc_slowdown_factor(isolated_runtime_1, isolated_runtime_2, coloc_runtime_1, coloc_runtime_2):\n",
    "    slowdown_1 = isolated_runtime_1 / coloc_runtime_1\n",
    "    slowdown_2 = isolated_runtime_2 / coloc_runtime_2\n",
    "    average_slowdown = calc_average_slowdown(slowdown_1, slowdown_2)\n",
    "    return average_slowdown\n",
    "\n",
    "def calc_affinity_score(isolated_runtime_1, coloc_runtime_1, isolated_runtime_2, coloc_runtime_2):\n",
    "    affinity_score = (isolated_runtime_1 + isolated_runtime_2) / (coloc_runtime_1 + coloc_runtime_2)\n",
    "    return min(1, affinity_score)\n",
    "    \n",
    "for name, result in coloc_benchmarking_results.items():\n",
    "    coloc_workload = result.get('workload')\n",
    "    # Find the isolated runtime for the same workload\n",
    "    isolated_runtime = ''\n",
    "    for iso_name, iso_result in isolated_benchmarking_results.items():\n",
    "        if iso_result.get('workload') == coloc_workload and iso_result.get('coloc_pair') is None:\n",
    "            isolated_runtime = iso_result.get('life_time')\n",
    "            break\n",
    "    result['isolated_runtime'] = isolated_runtime\n",
    "    result['isolated_power_consumption'] = 'not yet computed'\n",
    "    print(f\"Colocated benchmark: {coloc_workload}, {result.get('coloc_pair')}, Isolated runtime: {isolated_runtime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cec249dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not calculate for pair CpuMem: float() argument must be a string or a real number, not 'NoneType'\n",
      "Could not calculate for pair MemFileIO: float() argument must be a string or a real number, not 'NoneType'\n",
      "Could not calculate for pair FileIOCpu: float() argument must be a string or a real number, not 'NoneType'\n",
      "Could not calculate for pair CpuCpu: float() argument must be a string or a real number, not 'NoneType'\n",
      "Could not calculate for pair MemMem: float() argument must be a string or a real number, not 'NoneType'\n",
      "Could not calculate for pair FileIOFileIO: float() argument must be a string or a real number, not 'NoneType'\n",
      "{'CpuCpu': {'affinity_score': None,\n",
      "            'average_slowdown': None,\n",
      "            'colocated_runtime_1': None,\n",
      "            'colocated_runtime_2': None,\n",
      "            'isolated_runtime_1': 10.369488,\n",
      "            'isolated_runtime_2': 10.369488,\n",
      "            'power_consumption_1': 'not yet computed',\n",
      "            'power_consumption_2': 'not yet computed',\n",
      "            'workload_1': 'cpu',\n",
      "            'workload_2': 'cpu'},\n",
      " 'CpuMem': {'affinity_score': None,\n",
      "            'average_slowdown': None,\n",
      "            'colocated_runtime_1': None,\n",
      "            'colocated_runtime_2': None,\n",
      "            'isolated_runtime_1': 0.638697,\n",
      "            'isolated_runtime_2': 10.369488,\n",
      "            'power_consumption_1': 'not yet computed',\n",
      "            'power_consumption_2': 'not yet computed',\n",
      "            'workload_1': 'memory',\n",
      "            'workload_2': 'cpu'},\n",
      " 'FileIOCpu': {'affinity_score': None,\n",
      "               'average_slowdown': None,\n",
      "               'colocated_runtime_1': None,\n",
      "               'colocated_runtime_2': None,\n",
      "               'isolated_runtime_1': 0.168125,\n",
      "               'isolated_runtime_2': 10.369488,\n",
      "               'power_consumption_1': 'not yet computed',\n",
      "               'power_consumption_2': 'not yet computed',\n",
      "               'workload_1': 'fileio',\n",
      "               'workload_2': 'cpu'},\n",
      " 'FileIOFileIO': {'affinity_score': None,\n",
      "                  'average_slowdown': None,\n",
      "                  'colocated_runtime_1': None,\n",
      "                  'colocated_runtime_2': None,\n",
      "                  'isolated_runtime_1': 0.168125,\n",
      "                  'isolated_runtime_2': 0.168125,\n",
      "                  'power_consumption_1': 'not yet computed',\n",
      "                  'power_consumption_2': 'not yet computed',\n",
      "                  'workload_1': 'fileio',\n",
      "                  'workload_2': 'fileio'},\n",
      " 'MemFileIO': {'affinity_score': None,\n",
      "               'average_slowdown': None,\n",
      "               'colocated_runtime_1': None,\n",
      "               'colocated_runtime_2': None,\n",
      "               'isolated_runtime_1': 0.168125,\n",
      "               'isolated_runtime_2': 0.638697,\n",
      "               'power_consumption_1': 'not yet computed',\n",
      "               'power_consumption_2': 'not yet computed',\n",
      "               'workload_1': 'fileio',\n",
      "               'workload_2': 'memory'},\n",
      " 'MemMem': {'affinity_score': None,\n",
      "            'average_slowdown': None,\n",
      "            'colocated_runtime_1': None,\n",
      "            'colocated_runtime_2': None,\n",
      "            'isolated_runtime_1': 0.638697,\n",
      "            'isolated_runtime_2': 0.638697,\n",
      "            'power_consumption_1': 'not yet computed',\n",
      "            'power_consumption_2': 'not yet computed',\n",
      "            'workload_1': 'memory',\n",
      "            'workload_2': 'memory'}}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pprint\n",
    "\n",
    "# Transform benchmarking dict into a summary\n",
    "coloc_summary = defaultdict(dict)\n",
    "\n",
    "for name, result in coloc_benchmarking_results.items():\n",
    "    pair = result['coloc_pair']\n",
    "    workload = result.get('workload', 'unknown')\n",
    "    if 'workload_1' not in coloc_summary[pair]:\n",
    "        coloc_summary[pair]['workload_1'] = workload\n",
    "        coloc_summary[pair]['colocated_runtime_1'] = result.get('life_time')\n",
    "        coloc_summary[pair]['isolated_runtime_1'] = result.get('isolated_runtime')\n",
    "        coloc_summary[pair]['power_consumption_1'] = result.get('isolated_power_consumption')\n",
    "    else:\n",
    "        coloc_summary[pair]['workload_2'] = workload\n",
    "        coloc_summary[pair]['colocated_runtime_2'] = result.get('life_time')\n",
    "        coloc_summary[pair]['isolated_runtime_2'] = result.get('isolated_runtime')\n",
    "        coloc_summary[pair]['power_consumption_2'] = result.get('isolated_power_consumption')\n",
    "\n",
    "# Now calculate and add average_slowdown and affinity_score for each coloc pair\n",
    "for pair, summary in coloc_summary.items():\n",
    "    try:\n",
    "        iso1 = float(summary['isolated_runtime_1'])\n",
    "        iso2 = float(summary['isolated_runtime_2'])\n",
    "        coloc1 = float(summary['colocated_runtime_1'])\n",
    "        coloc2 = float(summary['colocated_runtime_2'])\n",
    "        summary['average_slowdown'] = calc_slowdown_factor(iso1, iso2, coloc1, coloc2)\n",
    "        summary['affinity_score'] = calc_affinity_score(iso1, coloc1, iso2, coloc2)\n",
    "    except Exception as e:\n",
    "        summary['average_slowdown'] = None\n",
    "        summary['affinity_score'] = None\n",
    "        print(f\"Could not calculate for pair {pair}: {e}\")\n",
    "\n",
    "coloc_summary = dict(coloc_summary)\n",
    "pprint.pprint(coloc_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharecomp-bB4WWry4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
